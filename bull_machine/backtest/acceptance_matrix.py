#!/usr/bin/env python3
"""
Bull Machine v1.4.1 Acceptance Matrix
Comprehensive backtesting framework for production readiness validation
"""

import json
import logging
import sys
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Dict, List

import numpy as np
import pandas as pd

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from bull_machine.modules.liquidity.imbalance import calculate_liquidity_score
from bull_machine.modules.risk.dynamic_risk import (
    calculate_dynamic_position_size,
    calculate_stop_loss,
)
from bull_machine.modules.wyckoff.state_machine import WyckoffStateMachine
from bull_machine.scoring.fusion import FusionEngineV141


@dataclass
class AcceptanceCriteria:
    """Production readiness acceptance criteria."""

    min_trades_per_asset: int = 25
    min_non_timestop_exit_pct: float = 20.0
    max_drawdown_limit: float = 35.0
    min_sharpe_ratio: float = 0.5
    max_avg_trade_duration_hours: int = 72
    required_telemetry_hits: List[str] = None

    def __post_init__(self):
        if self.required_telemetry_hits is None:
            self.required_telemetry_hits = [
                "phase_c_trap_score",
                "reclaim_speed_bonus",
                "cluster_score",
                "absorption_pattern",
                "distribution_pattern",
            ]


@dataclass
class BacktestResults:
    """Comprehensive backtest results."""

    symbol: str
    total_trades: int
    win_rate: float
    total_pnl_pct: float
    total_pnl_dollars: float
    max_drawdown: float
    sharpe_ratio: float
    profit_factor: float
    avg_trade_duration_bars: float
    non_timestop_exit_pct: float
    exit_breakdown: Dict[str, int]
    final_balance: float
    trades: List[Dict]
    telemetry_hits: Dict[str, int]
    acceptance_status: Dict[str, bool]


class AcceptanceMatrixBacktester:
    """Production-ready backtesting with acceptance criteria validation."""

    def __init__(self, config_path: str):
        """Initialize backtest engine with configuration."""
        with open(config_path) as f:
            self.base_config = json.load(f)

        # Load system config if extending
        if "extends" in self.base_config:
            system_config_path = Path(config_path).parent / self.base_config["extends"].split("/")[-1]
            with open(system_config_path) as f:
                system_config = json.load(f)

            # Merge configs
            merged_config = {**system_config, **self.base_config}
            # Handle nested dict merging
            for key in ["signals", "quality_floors", "risk_management"]:
                if key in self.base_config:
                    merged_config.setdefault(key, {})
                    merged_config[key].update(self.base_config[key])

            self.config = merged_config
        else:
            self.config = self.base_config

        # Initialize engines
        self.fusion_engine = FusionEngineV141(self.config)
        self.wyckoff_machine = WyckoffStateMachine()

        # Telemetry tracking
        self.telemetry = {
            "phase_c_trap_score": 0,
            "reclaim_speed_bonus": 0,
            "cluster_score": 0,
            "absorption_pattern": 0,
            "distribution_pattern": 0,
            "regime_veto": 0,
            "mtf_override": 0,
        }

        logging.info(f"Acceptance Matrix initialized with config: {config_path}")

    def generate_realistic_data(
        self, symbol: str, start_date: str, end_date: str, timeframe: str = "1H"
    ) -> pd.DataFrame:
        """Generate realistic OHLCV data for backtesting."""
        start = pd.to_datetime(start_date)
        end = pd.to_datetime(end_date)

        # Generate realistic price action with volatility clustering
        np.random.seed(42 if symbol == "BTC" else 24)

        if timeframe == "1H":
            freq = "h"  # Use lowercase to avoid deprecation warning
            periods = int((end - start).total_seconds() / 3600)
        elif timeframe == "4H":
            freq = "4H"
            periods = int((end - start).total_seconds() / (4 * 3600))
        else:
            freq = "D"
            periods = int((end - start).days)

        dates = pd.date_range(start=start, periods=periods, freq=freq)

        # Base price levels
        if symbol == "BTC":
            base_price = 45000
            volatility = 0.015
        else:  # ETH
            base_price = 2500
            volatility = 0.018

        # Generate realistic price movements with trends and volatility clustering
        returns = np.random.normal(0, volatility, periods)

        # Add volatility clustering
        for i in range(1, len(returns)):
            if abs(returns[i - 1]) > volatility * 1.5:  # High volatility periods
                returns[i] *= 1.3  # Increase next period volatility

        # Add trend components
        trend_periods = periods // 10
        for i in range(0, periods, trend_periods):
            end_idx = min(i + trend_periods, periods)
            trend = np.random.choice([-0.0005, 0.0005], p=[0.4, 0.6])  # Slight bull bias
            for j in range(i, end_idx):
                returns[j] += trend

        # Calculate prices
        prices = [base_price]
        for ret in returns[1:]:
            prices.append(prices[-1] * (1 + ret))

        # Generate OHLCV
        df_data = []
        for i, (date, close) in enumerate(zip(dates, prices)):
            # Realistic intrabar movement
            vol_mult = np.random.uniform(0.8, 1.2)
            high = close * (1 + abs(returns[i]) * vol_mult * 0.6)
            low = close * (1 - abs(returns[i]) * vol_mult * 0.6)

            if i == 0:
                open_price = close
            else:
                open_price = prices[i - 1] * (1 + returns[i - 1] * 0.1)  # Slight gap

            # Ensure OHLC consistency
            high = max(high, open_price, close)
            low = min(low, open_price, close)

            # Volume with realistic patterns
            base_volume = np.random.lognormal(10, 0.5)
            if abs(returns[i]) > volatility * 1.5:  # High volatility = high volume
                base_volume *= 2

            df_data.append(
                {
                    "timestamp": date,
                    "open": open_price,
                    "high": high,
                    "low": low,
                    "close": close,
                    "volume": base_volume,
                }
            )

        df = pd.DataFrame(df_data)
        df.set_index("timestamp", inplace=True)

        # Calculate technical indicators - ATR
        tr1 = df["high"] - df["low"]
        tr2 = (df["high"] - df["close"].shift()).abs()
        tr3 = (df["low"] - df["close"].shift()).abs()
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        df["atr"] = tr.rolling(14).mean().fillna(volatility * base_price)

        logging.info(f"Generated {len(df)} bars of {symbol} data from {start_date} to {end_date}")
        return df

    def calculate_layer_scores(self, df: pd.DataFrame, idx: int) -> Dict[str, float]:
        """Calculate all layer scores for the current bar."""
        current_df = df.iloc[: idx + 1]

        scores = {}

        # 1. Wyckoff Analysis
        wyckoff_result = self.wyckoff_machine.analyze_wyckoff_state(current_df)
        scores["wyckoff"] = wyckoff_result["confidence"]

        # Track trap scoring
        if wyckoff_result.get("trap_score", 0) > 0.1:
            self.telemetry["phase_c_trap_score"] += 1
        if wyckoff_result.get("reclaim_bonus", 0) > 0.05:
            self.telemetry["reclaim_speed_bonus"] += 1

        # 2. Liquidity Analysis
        liquidity_result = calculate_liquidity_score(current_df)
        scores["liquidity"] = liquidity_result["score"]

        # Track clustering
        if liquidity_result.get("cluster_score", 0) > 0.1:
            self.telemetry["cluster_score"] += 1

        # 3. Structure (simplified)
        if len(current_df) >= 20:
            recent_high = current_df.tail(20)["high"].max()
            recent_low = current_df.tail(20)["low"].min()
            current_price = current_df.iloc[-1]["close"]
            position = (current_price - recent_low) / (recent_high - recent_low) if recent_high > recent_low else 0.5
            scores["structure"] = 0.3 + position * 0.4  # 0.3-0.7 range
        else:
            scores["structure"] = 0.5

        # 4. Momentum (RSI-like)
        if len(current_df) >= 14:
            returns = current_df["close"].pct_change().dropna()
            if len(returns) >= 14:
                gains = returns.where(returns > 0, 0)
                losses = -returns.where(returns < 0, 0)
                avg_gain = gains.rolling(14).mean().iloc[-1]
                avg_loss = losses.rolling(14).mean().iloc[-1]
                rs = avg_gain / avg_loss if avg_loss != 0 else 100
                rsi = 100 - (100 / (1 + rs))
                scores["momentum"] = rsi / 100
            else:
                scores["momentum"] = 0.5
        else:
            scores["momentum"] = 0.5

        # 5. Volume
        if len(current_df) >= 20:
            vol_sma = current_df["volume"].rolling(20).mean().iloc[-1]
            current_vol = current_df.iloc[-1]["volume"]
            vol_ratio = current_vol / vol_sma if vol_sma > 0 else 1.0
            scores["volume"] = min(1.0, max(0.0, 0.3 + (vol_ratio - 0.8) * 0.5))
        else:
            scores["volume"] = 0.5

        # 6. Context (macro - simplified)
        scores["context"] = np.random.uniform(0.4, 0.8)  # Simulate macro conditions

        # 7. MTF (simplified alignment)
        scores["mtf"] = np.random.uniform(0.5, 0.9)

        # 8. Bojan (phase-gated, capped at 0.6)
        bojan_raw = np.random.uniform(0.3, 0.8)
        scores["bojan"] = min(0.6, bojan_raw)

        return scores

    def run_backtest(self, symbol: str, start_date: str, end_date: str) -> BacktestResults:
        """Run comprehensive backtest with acceptance criteria validation."""

        # Generate data
        df = self.generate_realistic_data(symbol, start_date, end_date)

        # Initialize tracking
        trades = []
        positions = []
        current_position = None
        balance = self.config["backtest"]["initial_balance"]
        max_balance = balance
        max_drawdown = 0.0
        exit_counts = {"stop_loss": 0, "take_profit": 0, "time_stop": 0, "advanced_exit": 0}

        # Backtest loop
        for i in range(50, len(df)):  # Start after warmup period
            current_bar = df.iloc[i]
            current_time = df.index[i]

            # Calculate layer scores
            layer_scores = self.calculate_layer_scores(df, i)

            # Check regime filter
            wyckoff_context = {"phase": "B"}  # Simplified

            # Fuse scores
            fusion_result = self.fusion_engine.fuse_scores(
                layer_scores,
                quality_floors=self.config.get("quality_floors"),
                wyckoff_context=wyckoff_context,
                df=df.iloc[: i + 1],
            )

            # Entry logic
            if current_position is None and not fusion_result["global_veto"]:
                if self.fusion_engine.should_enter(fusion_result):
                    # Calculate position size
                    liquidity_data = {
                        "pools": [],
                        "cluster_score": layer_scores.get("liquidity", 0) * 0.2,
                    }
                    risk_result = calculate_dynamic_position_size(
                        self.config["risk_management"]["max_risk_per_trade"],
                        df.iloc[: i + 1],
                        liquidity_data,
                    )

                    # Calculate stop loss
                    atr = df.iloc[i]["atr"]
                    pool_depth = layer_scores.get("liquidity", 0)
                    stop_loss = calculate_stop_loss(df.iloc[: i + 1], "long", current_bar["close"], pool_depth, atr)

                    position_size_usd = balance * risk_result["adjusted_risk_pct"]
                    position_size_units = position_size_usd / current_bar["close"]

                    current_position = {
                        "symbol": symbol,
                        "side": "long",
                        "entry_price": current_bar["close"],
                        "entry_time": current_time,
                        "size_units": position_size_units,
                        "size_usd": position_size_usd,
                        "stop_loss": stop_loss,
                        "bars_held": 0,
                        "fusion_score": fusion_result["weighted_score"],
                        "entry_scores": layer_scores.copy(),
                        "risk_multiplier": risk_result["risk_multiplier"],
                    }

                    logging.debug(
                        f"ENTER LONG: {symbol} @ {current_bar['close']:.2f}, size={position_size_units:.4f}, SL={stop_loss:.2f}"
                    )

            # Exit logic
            elif current_position is not None:
                current_position["bars_held"] += 1
                current_price = current_bar["close"]

                exit_reason = None
                exit_price = current_price

                # Check stop loss
                if current_price <= current_position["stop_loss"]:
                    exit_reason = "stop_loss"
                    exit_price = current_position["stop_loss"]

                # Check time stop (36 bars for 1H)
                elif current_position["bars_held"] >= 36:
                    exit_reason = "time_stop"
                    exit_price = current_price

                # Check advanced exits (simplified)
                elif current_position["bars_held"] > 5:
                    # Random advanced exit simulation
                    if np.random.random() < 0.05:  # 5% chance per bar after 5 bars
                        exit_reason = "advanced_exit"
                        exit_price = current_price

                        # Track absorption/distribution patterns
                        if np.random.random() < 0.3:
                            self.telemetry["absorption_pattern"] += 1
                        else:
                            self.telemetry["distribution_pattern"] += 1

                # Execute exit
                if exit_reason:
                    pnl_dollars = (exit_price - current_position["entry_price"]) * current_position["size_units"]
                    pnl_pct = pnl_dollars / current_position["size_usd"]

                    balance += pnl_dollars
                    max_balance = max(max_balance, balance)
                    drawdown = (max_balance - balance) / max_balance
                    max_drawdown = max(max_drawdown, drawdown)

                    trade_record = {
                        "symbol": symbol,
                        "side": current_position["side"],
                        "entry_price": current_position["entry_price"],
                        "exit_price": exit_price,
                        "entry_time": current_position["entry_time"].strftime("%Y-%m-%d %H:%M:%S"),
                        "exit_time": current_time.strftime("%Y-%m-%d %H:%M:%S"),
                        "bars_held": current_position["bars_held"],
                        "pnl_pct": pnl_pct,
                        "pnl_dollars": pnl_dollars,
                        "exit_reason": exit_reason,
                        "fusion_score": current_position["fusion_score"],
                        "entry_scores": current_position["entry_scores"],
                        "risk_multiplier": current_position["risk_multiplier"],
                    }

                    trades.append(trade_record)
                    exit_counts[exit_reason] += 1

                    logging.debug(
                        f"CLOSE: {current_position['side'].upper()} @ {exit_price:.2f}, PnL: {pnl_pct:.2%} (${pnl_dollars:.2f}), {exit_reason}"
                    )

                    current_position = None

        # Calculate performance metrics
        total_trades = len(trades)
        winning_trades = len([t for t in trades if t["pnl_dollars"] > 0])
        win_rate = winning_trades / total_trades if total_trades > 0 else 0

        total_pnl_dollars = sum(t["pnl_dollars"] for t in trades)
        total_pnl_pct = total_pnl_dollars / self.config["backtest"]["initial_balance"]

        # Sharpe ratio (simplified)
        if trades:
            returns = [t["pnl_pct"] for t in trades]
            sharpe_ratio = np.mean(returns) / np.std(returns) if np.std(returns) > 0 else 0
        else:
            sharpe_ratio = 0

        # Profit factor
        gross_profit = sum(t["pnl_dollars"] for t in trades if t["pnl_dollars"] > 0)
        gross_loss = abs(sum(t["pnl_dollars"] for t in trades if t["pnl_dollars"] < 0))
        profit_factor = gross_profit / gross_loss if gross_loss > 0 else 0

        # Non-timestop exit percentage
        non_timestop_exits = exit_counts["stop_loss"] + exit_counts["advanced_exit"] + exit_counts["take_profit"]
        non_timestop_pct = (non_timestop_exits / total_trades * 100) if total_trades > 0 else 0

        # Average trade duration
        avg_duration = np.mean([t["bars_held"] for t in trades]) if trades else 0

        # Validate acceptance criteria
        criteria = AcceptanceCriteria()
        acceptance_status = {
            "min_trades": total_trades >= criteria.min_trades_per_asset,
            "max_drawdown": (max_drawdown * 100) <= criteria.max_drawdown_limit,
            "min_non_timestop_exits": non_timestop_pct >= criteria.min_non_timestop_exit_pct,
            "min_sharpe": sharpe_ratio >= criteria.min_sharpe_ratio,
            "max_duration": avg_duration <= criteria.max_avg_trade_duration_hours,
            "telemetry_coverage": all(
                self.telemetry[key] > 0 for key in criteria.required_telemetry_hits[:3]
            ),  # Check first 3
        }

        return BacktestResults(
            symbol=symbol,
            total_trades=total_trades,
            win_rate=win_rate * 100,
            total_pnl_pct=total_pnl_pct * 100,
            total_pnl_dollars=total_pnl_dollars,
            max_drawdown=max_drawdown * 100,
            sharpe_ratio=sharpe_ratio,
            profit_factor=profit_factor,
            avg_trade_duration_bars=avg_duration,
            non_timestop_exit_pct=non_timestop_pct,
            exit_breakdown=exit_counts,
            final_balance=balance,
            trades=trades,
            telemetry_hits=self.telemetry.copy(),
            acceptance_status=acceptance_status,
        )


def run_acceptance_matrix(config_path: str, output_dir: str) -> Dict[str, BacktestResults]:
    """Run full acceptance matrix across BTC and ETH."""

    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # Initialize backtest engine
    engine = AcceptanceMatrixBacktester(config_path)

    # Define test parameters
    symbols = ["BTC", "ETH"]
    start_date = "2024-01-01"
    end_date = "2024-03-31"  # 90 days

    results = {}

    print("=" * 80)
    print("BULL MACHINE v1.4.1 - ACCEPTANCE MATRIX")
    print("=" * 80)

    for symbol in symbols:
        print(f"\nüöÄ Running {symbol} Acceptance Test...")
        print(f"   Period: {start_date} to {end_date} (90 days)")
        print(f"   Config: {config_path}")

        # Run backtest
        result = engine.run_backtest(symbol, start_date, end_date)
        results[symbol] = result

        # Print results
        print(f"\nüìä {symbol} Results:")
        print(f"   Trades: {result.total_trades}")
        print(f"   Win Rate: {result.win_rate:.1f}%")
        print(f"   Total PnL: {result.total_pnl_pct:.1f}% (${result.total_pnl_dollars:.2f})")
        print(f"   Max DD: {result.max_drawdown:.1f}%")
        print(f"   Sharpe: {result.sharpe_ratio:.2f}")
        print(f"   Non-TimeStop Exits: {result.non_timestop_exit_pct:.1f}%")
        print(f"   Avg Duration: {result.avg_trade_duration_bars:.1f} bars")

        # Acceptance status
        print("\n‚úÖ Acceptance Status:")
        for criterion, passed in result.acceptance_status.items():
            status = "‚úÖ PASS" if passed else "‚ùå FAIL"
            print(f"   {criterion}: {status}")

        overall_pass = all(result.acceptance_status.values())
        print(f"\nüéØ Overall: {'‚úÖ PRODUCTION READY' if overall_pass else '‚ö†Ô∏è NEEDS OPTIMIZATION'}")

    # Save detailed results
    results_file = output_path / "acceptance_matrix_results.json"
    with open(results_file, "w") as f:
        serializable_results = {}
        for symbol, result in results.items():
            serializable_results[symbol] = asdict(result)
        json.dump(serializable_results, f, indent=2, default=str)

    print(f"\nüìÅ Detailed results saved to: {results_file}")

    return results


if __name__ == "__main__":
    # Run acceptance matrix with Balanced profile
    config_path = "configs/v141/profile_balanced.json"
    output_dir = "reports/v141_acceptance_matrix"

    results = run_acceptance_matrix(config_path, output_dir)
