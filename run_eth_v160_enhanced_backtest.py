#!/usr/bin/env python3
"""
Bull Machine v1.6.0 - ETH Enhanced Ensemble Backtest with v1.6.0 Signals
üöÄ Integrates M1/M2 Wyckoff + Hidden Fibonacci + Volatility-Weighted Scoring
Target: Hit remaining RC targets (WR ‚â•50%, PnL ‚â•10%, PF ‚â•1.3, Sharpe ‚â•2.2)
"""

import pandas as pd
import numpy as np
import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from bull_machine.modules.fusion.v151_core_trader import CoreTraderV151
from bull_machine.backtest.ensemble_mode import EnsembleAligner
from bull_machine.strategy.atr_exits import enhanced_exit_check
from bull_machine.strategy.wyckoff_m1m2 import compute_m1m2_scores
from bull_machine.strategy.hidden_fibs import compute_hidden_fib_scores

def load_and_align_eth_data() -> pd.DataFrame:
    """Load ETH data from multiple timeframes and align."""

    print("üìä Loading ETH Multi-Timeframe Data...")

    # ETH data files
    data_files = {
        "1D": "/Users/raymondghandchi/Desktop/Chart Logs/COINBASE_ETHUSD, 1D_fa116.csv",
        "4H": "/Users/raymondghandchi/Desktop/Chart Logs/COINBASE_ETHUSD, 240_ab8a9.csv",
        "1H": "/Users/raymondghandchi/Downloads/Chart logs 2/COINBASE_ETHUSD, 60_2f4ab.csv"
    }

    timeframes = {}

    for tf, file_path in data_files.items():
        print(f"Loading {tf}...")

        if not Path(file_path).exists():
            print(f"‚ùå {tf} file not found: {file_path}")
            continue

        df = pd.read_csv(file_path)

        # Handle timestamp
        if 'time' in df.columns:
            df['timestamp'] = pd.to_datetime(df['time'], unit='s')
        elif 'timestamp' not in df.columns:
            df['timestamp'] = pd.date_range(start='2020-01-01', periods=len(df), freq='h')

        # Handle volume
        if 'volume' not in df.columns:
            if 'BUY+SELL V' in df.columns:
                df['volume'] = df['BUY+SELL V']
            else:
                df['volume'] = df['close'] * 100

        # Clean data
        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']].dropna()
        df = df.sort_values('timestamp').reset_index(drop=True)

        # Rename columns with TF suffix
        df_renamed = df.rename(columns={
            'open': f'open_{tf}',
            'high': f'high_{tf}',
            'low': f'low_{tf}',
            'close': f'close_{tf}',
            'volume': f'volume_{tf}'
        })

        timeframes[tf] = df_renamed
        print(f"‚úÖ {tf}: {len(df)} bars ({df['timestamp'].min()} to {df['timestamp'].max()})")

    if len(timeframes) < 3:
        raise ValueError("Need all three timeframes for ensemble trading")

    # Find overlapping period
    start_times = [df['timestamp'].min() for df in timeframes.values()]
    end_times = [df['timestamp'].max() for df in timeframes.values()]

    overlap_start = max(start_times)
    overlap_end = min(end_times)

    print(f"\nüìÖ Overlap Period: {overlap_start} to {overlap_end}")

    # Use 1H as base for alignment
    base_df = timeframes['1H'].copy()
    base_df = base_df[
        (base_df['timestamp'] >= overlap_start) &
        (base_df['timestamp'] <= overlap_end)
    ].reset_index(drop=True)

    # Align 4H data
    base_df['timestamp_4H'] = base_df['timestamp'].dt.floor('4h')
    df_4h_aligned = timeframes['4H'].copy()
    df_4h_aligned['timestamp_4H'] = df_4h_aligned['timestamp'].dt.floor('4h')

    base_df = base_df.merge(
        df_4h_aligned[['timestamp_4H', 'open_4H', 'high_4H', 'low_4H', 'close_4H', 'volume_4H']],
        on='timestamp_4H',
        how='left'
    )

    # Align 1D data
    base_df['timestamp_1D'] = base_df['timestamp'].dt.floor('1D')
    df_1d_aligned = timeframes['1D'].copy()
    df_1d_aligned['timestamp_1D'] = df_1d_aligned['timestamp'].dt.floor('1D')

    base_df = base_df.merge(
        df_1d_aligned[['timestamp_1D', 'open_1D', 'high_1D', 'low_1D', 'close_1D', 'volume_1D']],
        on='timestamp_1D',
        how='left'
    )

    # Forward fill missing data
    base_df = base_df.ffill()
    base_df = base_df.dropna()

    print(f"‚úÖ Aligned Dataset: {len(base_df)} 1H bars")
    print(f"üí∞ ETH Price Range: ${base_df['close_1H'].min():.2f} - ${base_df['close_1H'].max():.2f}")

    return base_df

def get_eth_ensemble_config() -> Dict:
    """Get ETH v1.6.0 enhanced ensemble configuration with M1/M2 Wyckoff + Hidden Fibonacci signals."""

    config = {
        "entry_threshold": 0.35,  # Lower threshold for v1.6.0 enhanced signals
        "quality_floors": {
            "wyckoff": 0.15,  # Lower for enhanced M1/M2 integration
            "liquidity": 0.15,
            "structure": 0.15,
            "momentum": 0.20,
            "volume": 0.15,
            "context": 0.15,
            "mtf": 0.20,
            # v1.6.0 enhanced signals - ALLOW ZERO for initial testing
            "m1": 0.0,   # Allow zero M1 (markup phases)
            "m2": 0.0,   # Allow zero M2 (spring phases)
            "fib_retracement": 0.15,  # Allow modest fib levels
            "fib_extension": 0.15
        },
        "features": {
            "mtf_dl2": True,
            "six_candle_leg": True,
            "orderflow_lca": False,  # Disabled for ensemble
            "negative_vip": False,   # Disabled for ensemble
            "wyckoff_phase": True,
            "liquidity_sweep": False,
            "order_blocks": False,
            "wick_magnet": True,
            "live_data": False,
            "use_asset_profiles": True,
            "atr_sizing": True,
            "atr_exits": True
        },
        "risk": {
            "risk_pct": 0.005,  # 0.5% risk per trade
            "atr_window": 14,
            "sl_atr": 1.8,
            "tp_atr": 3.0,
            "trail_atr": 1.2,
            "profit_ladder": [
                {"ratio": 1.5, "percent": 0.25},
                {"ratio": 2.5, "percent": 0.50},
                {"ratio": 4.0, "percent": 0.25}
            ]
        },
        "regime": {
            "vol_ratio_min": 1.0,
            "atr_pct_max": 0.08
        },
        "ensemble": {
            "enabled": True,
            "min_consensus": 2,        # 2 of 3 TFs must agree (proper ensemble)
            "consensus_penalty": 0.01, # -1% score when only 2/3 agree (more lenient)
            "rolling_k": 2,           # Need 2 of last 5 bars (more lenient)
            "rolling_n": 5,
            "lead_lag_window": 5,     # HTF can confirm within 5 bars (more lenient)
            "dynamic_thresholds": True # Enable volatility-based thresholds
        },
        "cooldown_bars": 168,  # 168H (7 day) cooldown between trades
        "timeframe": "ensemble"
    }

    return config

def generate_ensemble_signal(df_aligned: pd.DataFrame, i: int, traders: Dict, aligner: EnsembleAligner) -> Optional[Dict]:
    """Generate time-tolerant ensemble signal."""

    if i < 200:  # Need sufficient history
        return None

    history_length = min(200, i)

    # Extract timeframe data
    tf_data = {}

    # 1H data (most granular)
    tf_data['1H'] = pd.DataFrame({
        'timestamp': df_aligned['timestamp'].iloc[i-history_length:i+1],
        'open': df_aligned['open_1H'].iloc[i-history_length:i+1],
        'high': df_aligned['high_1H'].iloc[i-history_length:i+1],
        'low': df_aligned['low_1H'].iloc[i-history_length:i+1],
        'close': df_aligned['close_1H'].iloc[i-history_length:i+1],
        'volume': df_aligned['volume_1H'].iloc[i-history_length:i+1]
    }).reset_index(drop=True)

    # 4H data
    tf_data['4H'] = pd.DataFrame({
        'timestamp': df_aligned['timestamp'].iloc[i-history_length:i+1:4],
        'open': df_aligned['open_4H'].iloc[i-history_length:i+1:4],
        'high': df_aligned['high_4H'].iloc[i-history_length:i+1:4],
        'low': df_aligned['low_4H'].iloc[i-history_length:i+1:4],
        'close': df_aligned['close_4H'].iloc[i-history_length:i+1:4],
        'volume': df_aligned['volume_4H'].iloc[i-history_length:i+1:4]
    }).reset_index(drop=True)

    # 1D data
    tf_data['1D'] = pd.DataFrame({
        'timestamp': df_aligned['timestamp'].iloc[i-history_length:i+1:24],
        'open': df_aligned['open_1D'].iloc[i-history_length:i+1:24],
        'high': df_aligned['high_1D'].iloc[i-history_length:i+1:24],
        'low': df_aligned['low_1D'].iloc[i-history_length:i+1:24],
        'close': df_aligned['close_1D'].iloc[i-history_length:i+1:24],
        'volume': df_aligned['volume_1D'].iloc[i-history_length:i+1:24]
    }).reset_index(drop=True)

    # Generate scores for each timeframe
    tf_scores = {}

    try:
        for tf in ['1H', '4H', '1D']:
            if tf in traders and len(tf_data[tf]) > 50:
                # Get base v1.5.1 scores
                scores = traders[tf].compute_base_scores(tf_data[tf])

                # Add v1.6.0 enhanced signals FIRST (before quality floor checks)
                try:
                    # M1/M2 Wyckoff phase detection
                    m1m2_scores = compute_m1m2_scores(tf_data[tf], tf)
                    scores.update(m1m2_scores)

                    # Hidden Fibonacci zones
                    fib_scores = compute_hidden_fib_scores(tf_data[tf], tf)
                    scores.update(fib_scores)

                    # Enhanced Wyckoff scoring: blend traditional + M1/M2
                    traditional_wyckoff = scores.get('wyckoff', 0.25)
                    m1_score = m1m2_scores.get('m1', 0.0)
                    m2_score = m1m2_scores.get('m2', 0.0)

                    # Boost Wyckoff with M1/M2 confluence
                    enhanced_wyckoff = traditional_wyckoff + (m1_score * 0.3) + (m2_score * 0.3)
                    scores['wyckoff'] = min(1.0, enhanced_wyckoff)  # Cap at 1.0

                    # Log enhanced signals for analysis
                    if m1m2_scores.get('m1', 0) > 0.3 or m1m2_scores.get('m2', 0) > 0.3:
                        print(f"üéØ Bar {i} {tf} M1/M2: M1={m1m2_scores.get('m1', 0):.2f} M2={m1m2_scores.get('m2', 0):.2f}")
                        # Also show current score state
                        print(f"   Score Integration: scores['m1']={scores.get('m1', 'MISSING')} scores['m2']={scores.get('m2', 'MISSING')}")
                    if fib_scores.get('fib_retracement', 0) > 0.3 or fib_scores.get('fib_extension', 0) > 0.3:
                        print(f"üìê Bar {i} {tf} Fib: R={fib_scores.get('fib_retracement', 0):.2f} E={fib_scores.get('fib_extension', 0):.2f}")
                        print(f"   Score Integration: scores['fib_retracement']={scores.get('fib_retracement', 'MISSING')} scores['fib_extension']={scores.get('fib_extension', 'MISSING')}")

                    # DEBUG: Show all scores for analysis
                    if i % 50 == 0:  # Every 50 bars
                        print(f"\nüîç DEBUG {tf} Bar {i}:")
                        print(f"   Traditional: wyck={scores.get('wyckoff', 0):.3f}")
                        print(f"   Enhanced: M1={m1m2_scores.get('m1', 0):.3f} M2={m1m2_scores.get('m2', 0):.3f}")
                        print(f"   Final Enhanced Wyckoff: {scores.get('wyckoff', 0):.3f}")
                        print(f"   All scores: {dict((k, f'{v:.2f}') for k, v in scores.items())}")

                except Exception as enhance_e:
                    print(f"‚ö†Ô∏è  {tf} v1.6.0 enhancement error: {enhance_e}")
                    # Add default enhanced values only if they don't exist
                    if 'm1' not in scores:
                        scores.update({'m1': 0.0, 'm2': 0.0, 'fib_retracement': 0.0, 'fib_extension': 0.0})

                # Debug: Verify score assignment
                if m1m2_scores.get('m1', 0) > 0.3 or m1m2_scores.get('m2', 0) > 0.3:
                    print(f"   üìù PRE-ASSIGNMENT {tf}: scores={dict((k, f'{v:.2f}') for k, v in scores.items() if k in ['m1', 'm2'])}")

                tf_scores[tf] = scores.copy()  # Make explicit copy

                if m1m2_scores.get('m1', 0) > 0.3 or m1m2_scores.get('m2', 0) > 0.3:
                    print(f"   üìù POST-ASSIGNMENT {tf}: tf_scores[{tf}]={dict((k, f'{v:.2f}') for k, v in tf_scores[tf].items() if k in ['m1', 'm2'])}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Error generating TF scores: {e}")
        return None

    if len(tf_scores) < 2:
        return None

    # Update ensemble aligner
    aligner.update(tf_scores)

    # DEBUG: Log ensemble decision details every 100 bars
    if i % 100 == 0:
        print(f"\nüìä ENSEMBLE DEBUG Bar {i}:")
        for tf, scores in tf_scores.items():
            failed = []
            config = get_eth_ensemble_config()
            floors = config.get('quality_floors', {})
            for layer, floor in floors.items():
                if scores.get(layer, 0) < floor:
                    failed.append(f"{layer}({scores.get(layer, 0):.2f}<{floor:.2f})")
            if failed:
                print(f"   {tf} FAILED: {failed}")
            else:
                print(f"   {tf} PASSED: avg_score={sum(scores.values())/len(scores):.3f}")

    # DEBUG: Show exact tf_scores being passed to ensemble
    if i % 100 == 0:
        print(f"üî• FIRE INPUT Bar {i}: tf_scores = {dict((tf, dict((k, f'{v:.2f}') for k, v in scores.items() if k in ['m1', 'm2', 'fib_retracement', 'fib_extension'])) for tf, scores in tf_scores.items())}")

    # FORCE EXPLICIT WAIT - Ensure all enhanced computations complete
    import time
    time.sleep(0.001)  # 1ms delay to ensure completion

    # Final verification: Check that enhanced signals are present
    enhanced_signal_present = False
    for tf, scores in tf_scores.items():
        if scores.get('m1', 0) > 0.3 or scores.get('m2', 0) > 0.3 or scores.get('fib_retracement', 0) > 0.3:
            enhanced_signal_present = True
            break

    if enhanced_signal_present and i % 50 == 0:
        print(f"üö® ENHANCED SIGNAL PRESENT Bar {i}: tf_scores ready for ensemble")

    # v1.6.0 ENHANCED ENSEMBLE LOGIC
    # Check for strong enhanced signals that should override traditional requirements
    strong_enhanced_signal = False
    enhanced_score = 0.0

    for tf, scores in tf_scores.items():
        # M1 springs (0.5+) or M2 markup (0.4+) or strong Fibonacci confluence (0.4+)
        if scores.get('m1', 0) > 0.5 or scores.get('m2', 0) > 0.4 or scores.get('fib_retracement', 0) > 0.4:
            strong_enhanced_signal = True
            enhanced_score = max(enhanced_score,
                                max(scores.get('m1', 0), scores.get('m2', 0), scores.get('fib_retracement', 0)))
            print(f"üéØ ENHANCED TRIGGER {tf} - M1:{scores.get('m1', 0):.2f} M2:{scores.get('m2', 0):.2f} FibR:{scores.get('fib_retracement', 0):.2f}")

    if strong_enhanced_signal:
        # Enhanced signals detected - use relaxed ensemble requirements
        fire = True
        ensemble_score = 0.35 + enhanced_score  # Base + enhanced boost
        print(f"‚úÖ v1.6.0 ENHANCED FIRE: score={ensemble_score:.3f}")
    else:
        # No strong enhanced signals - use traditional ensemble logic
        fire, ensemble_score = aligner.fire(tf_scores, tf_data)

    if not fire:
        return None

    # Use 1H data for precise entry execution
    entry_price = df_aligned.iloc[i]['close_1H']

    # Determine side based on momentum
    momentum_scores = [tf_scores[tf].get('momentum', 0.5) for tf in tf_scores.keys()]
    avg_momentum = np.mean(momentum_scores)
    side = "LONG" if avg_momentum >= 0.5 else "SHORT"

    # Calculate position size using ATR
    current_atr = tf_data['1H']['high'].tail(14).mean() - tf_data['1H']['low'].tail(14).mean()
    if current_atr <= 0:
        current_atr = entry_price * 0.02  # 2% fallback

    risk_amount = 10000 * 0.005  # 0.5% of 10k balance
    stop_distance = current_atr * 1.8  # 1.8 ATR stop

    if side == "long":
        stop_loss = entry_price - stop_distance
    else:
        stop_loss = entry_price + stop_distance

    quantity = risk_amount / abs(entry_price - stop_loss)

    return {
        "side": side,
        "entry_price": entry_price,
        "quantity": quantity,
        "stop_loss": stop_loss,
        "ensemble_score": ensemble_score,
        "tf_scores": tf_scores,
        "participating_tfs": list(tf_scores.keys()),
        "consensus_strength": len(tf_scores)
    }

def run_eth_ensemble_backtest(df_aligned: pd.DataFrame) -> Dict:
    """Run ETH ensemble backtest with time-tolerant logic."""

    print(f"\nüöÄ Running ETH Ensemble Backtest...")

    config = get_eth_ensemble_config()

    # Initialize traders for each timeframe
    traders = {}
    for tf in ['1H', '4H', '1D']:
        tf_config = config.copy()
        tf_config['timeframe'] = tf
        traders[tf] = CoreTraderV151(tf_config)

    # Initialize ensemble aligner
    aligner = EnsembleAligner(config)

    # Trading state
    balance = 10000.0
    active_position = None
    trades = []
    signals_generated = 0
    last_trade_bar = -999
    equity_curve = [balance]
    peak_balance = balance

    # Process each aligned bar
    for i in range(200, len(df_aligned)):
        current_bar = df_aligned.iloc[i]

        # Check exits first
        if active_position:
            # Use 1H data for exits
            exit_history = pd.DataFrame({
                'timestamp': df_aligned['timestamp'].iloc[max(0,i-100):i+1],
                'open': df_aligned['open_1H'].iloc[max(0,i-100):i+1],
                'high': df_aligned['high_1H'].iloc[max(0,i-100):i+1],
                'low': df_aligned['low_1H'].iloc[max(0,i-100):i+1],
                'close': df_aligned['close_1H'].iloc[max(0,i-100):i+1],
                'volume': df_aligned['volume_1H'].iloc[max(0,i-100):i+1]
            })

            # Determine dominant timeframe for exit strategy
            dominant_tf = '1H'  # Default to 1H since we're using 1H bars
            if 'participating_tfs' in active_position:
                if '1D' in active_position['participating_tfs']:
                    dominant_tf = '1D'  # Use 1D exit strategy if 1D participated
                elif '4H' in active_position['participating_tfs']:
                    dominant_tf = '4H'  # Use 4H exit strategy if 4H participated

            exit_result = enhanced_exit_check(exit_history, active_position, config, tf=dominant_tf)

            if exit_result.get("close_position", False):
                closed_percent = exit_result.get("closed_percent", 1.0)
                exit_price = exit_result.get("exit_price", current_bar["close_1H"])
                entry_price = active_position["entry_price"]

                if active_position["side"] == "LONG":
                    pnl_pct = (exit_price - entry_price) / entry_price * 100
                else:
                    pnl_pct = (entry_price - exit_price) / entry_price * 100

                # Calculate dollar P&L for the portion being closed
                position_value = active_position["quantity"] * entry_price
                pnl_dollar = position_value * (pnl_pct / 100) * closed_percent
                balance += pnl_dollar

                # Record trade (partial or full)
                trade_record = {
                    **active_position,
                    "exit_timestamp": current_bar["timestamp"],
                    "exit_bar": i,
                    "exit_price": exit_price,
                    "exit_reason": exit_result.get("reason", "unknown"),
                    "pnl_pct": pnl_pct,
                    "pnl_dollar": pnl_dollar,
                    "bars_held": i - active_position["entry_bar"],
                    "closed_percent": closed_percent
                }
                trades.append(trade_record)

                print(f"EXIT: {active_position['side'].upper()} @ ${exit_price:.2f} "
                      f"({exit_result.get('reason', 'unknown')}) | "
                      f"PnL: {pnl_pct:+.2f}% (${pnl_dollar:+.2f}) | "
                      f"TFs: {active_position.get('participating_tfs', [])}")

                # Handle partial vs full exit
                if closed_percent >= 1.0 or exit_result.get("reason") in ["stop_loss", "wick_magnet", "trailing_stop"]:
                    # Full exit
                    active_position = None
                    last_trade_bar = i
                else:
                    # Partial exit - reduce position size
                    active_position["size"] *= (1.0 - closed_percent)
                    active_position["quantity"] *= (1.0 - closed_percent)

        # Generate ensemble signals
        if not active_position:
            # Check cooldown
            if i - last_trade_bar < config["cooldown_bars"]:
                continue

            ensemble_signal = generate_ensemble_signal(df_aligned, i, traders, aligner)

            if ensemble_signal:
                signals_generated += 1

                # Execute trade
                active_position = {
                    "entry_timestamp": current_bar["timestamp"],
                    "entry_bar": i,
                    **ensemble_signal
                }
                active_position["initial_stop_loss"] = ensemble_signal["stop_loss"]
                active_position["size"] = 1.0  # Full position size for tracking partial exits

                print(f"ENSEMBLE ENTRY: {ensemble_signal['side'].upper()} @ ${ensemble_signal['entry_price']:.2f} | "
                      f"Qty: {ensemble_signal['quantity']:.4f} | "
                      f"Score: {ensemble_signal['ensemble_score']:.3f} | "
                      f"TFs: {ensemble_signal['participating_tfs']} | "
                      f"Consensus: {ensemble_signal['consensus_strength']}/3")

                last_trade_bar = i

        # Update equity curve
        current_equity = balance
        if active_position:
            current_price = current_bar["close_1H"]
            entry_price = active_position["entry_price"]

            if active_position["side"] == "LONG":
                unrealized_pnl = (current_price - entry_price) / entry_price
            else:
                unrealized_pnl = (entry_price - current_price) / entry_price

            position_value = active_position["quantity"] * entry_price
            current_equity += position_value * unrealized_pnl

        equity_curve.append(current_equity)
        if current_equity > peak_balance:
            peak_balance = current_equity

    # Calculate final metrics
    total_trades = len(trades)
    winning_trades = len([t for t in trades if t["pnl_pct"] > 0])
    win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0

    total_return_pct = (balance - 10000.0) / 10000.0 * 100

    # Max drawdown
    max_drawdown = 0
    for equity in equity_curve:
        if peak_balance > 0:
            drawdown = (peak_balance - equity) / peak_balance * 100
            max_drawdown = max(max_drawdown, drawdown)

    # Win/loss metrics
    wins = [t["pnl_pct"] for t in trades if t["pnl_pct"] > 0]
    losses = [t["pnl_pct"] for t in trades if t["pnl_pct"] <= 0]

    avg_win = np.mean(wins) if wins else 0
    avg_loss = np.mean(losses) if losses else 0

    profit_factor = 0
    if avg_loss < 0 and len(losses) > 0:
        total_wins = sum(wins) if wins else 0
        total_losses = abs(sum(losses))
        profit_factor = total_wins / total_losses if total_losses > 0 else float('inf')

    # Trading frequency
    days_traded = (df_aligned.iloc[-1]["timestamp"] - df_aligned.iloc[0]["timestamp"]).days
    trades_per_month = (total_trades / days_traded * 30) if days_traded > 0 else 0

    # Sharpe ratio
    returns = np.diff(equity_curve) / np.array(equity_curve[:-1])
    returns = returns[~np.isnan(returns)]
    sharpe_ratio = 0
    if len(returns) > 0 and np.std(returns) > 0:
        sharpe_ratio = (np.mean(returns) / np.std(returns)) * np.sqrt(252 * 24)  # Hourly data

    return {
        "total_bars": len(df_aligned),
        "signals_generated": signals_generated,
        "total_trades": total_trades,
        "winning_trades": winning_trades,
        "win_rate": win_rate,
        "trades_per_month": trades_per_month,
        "initial_balance": 10000.0,
        "final_balance": balance,
        "total_return_pct": total_return_pct,
        "max_drawdown": max_drawdown,
        "avg_win": avg_win,
        "avg_loss": avg_loss,
        "profit_factor": profit_factor,
        "sharpe_ratio": sharpe_ratio,
        "trades": trades,
        "equity_curve": equity_curve
    }

def main():
    """Run ETH time-tolerant ensemble backtest."""
    print("="*70)
    print("üöÄ Bull Machine v1.5.1 - ETH Time-Tolerant Ensemble Backtest")
    print("üìä Testing realistic MTF alignment with lead-lag tolerance")
    print("üéØ Target: 2-4 trades/month, ‚â•50% WR, ‚â•10% return")
    print("="*70)

    try:
        # Load and align ETH data
        df_aligned = load_and_align_eth_data()

        # Run ensemble backtest
        results = run_eth_ensemble_backtest(df_aligned)

        # Display results
        print(f"\n{'='*60}")
        print(f"üìà ETH ENSEMBLE BACKTEST RESULTS")
        print(f"{'='*60}")

        print(f"  üìÖ Period: {df_aligned['timestamp'].min().strftime('%Y-%m-%d')} to {df_aligned['timestamp'].max().strftime('%Y-%m-%d')}")
        print(f"  üìä Total 1H Bars: {results['total_bars']:,}")
        print(f"  üéØ Ensemble Signals: {results['signals_generated']}")
        print(f"  üíº Trades Executed: {results['total_trades']}")
        print(f"  üèÜ Win Rate: {results['win_rate']:.1f}% ({results['winning_trades']}/{results['total_trades']})")
        print(f"  üìÖ Trading Frequency: {results['trades_per_month']:.2f} trades/month")
        print(f"  üí∞ Starting Balance: ${results['initial_balance']:,.2f}")
        print(f"  üí∞ Final Balance: ${results['final_balance']:,.2f}")
        print(f"  üìà Total Return: {results['total_return_pct']:+.2f}%")
        print(f"  üìâ Max Drawdown: {results['max_drawdown']:.2f}%")
        print(f"  ‚¨ÜÔ∏è  Avg Win: {results['avg_win']:+.2f}%")
        print(f"  ‚¨áÔ∏è  Avg Loss: {results['avg_loss']:+.2f}%")
        print(f"  ‚öñÔ∏è  Profit Factor: {results['profit_factor']:.2f}")
        print(f"  üìä Sharpe Ratio: {results['sharpe_ratio']:.2f}")

        # Check RC targets
        print(f"\n{'='*60}")
        print(f"üéØ RC PROMOTION TARGET ANALYSIS")
        print(f"{'='*60}")

        targets_met = 0
        total_targets = 6

        # Trading frequency (2-4 trades/month)
        freq_met = 2.0 <= results['trades_per_month'] <= 4.0
        print(f"  ‚úÖ Trading Frequency: {results['trades_per_month']:.2f}/month {'‚úÖ' if freq_met else '‚ùå'} (Target: 2-4)")
        if freq_met: targets_met += 1

        # Win rate (‚â•50%)
        wr_met = results['win_rate'] >= 50.0
        print(f"  ‚úÖ Win Rate: {results['win_rate']:.1f}% {'‚úÖ' if wr_met else '‚ùå'} (Target: ‚â•50%)")
        if wr_met: targets_met += 1

        # Total return (‚â•10%)
        return_met = results['total_return_pct'] >= 10.0
        print(f"  ‚úÖ Total Return: {results['total_return_pct']:+.2f}% {'‚úÖ' if return_met else '‚ùå'} (Target: ‚â•10%)")
        if return_met: targets_met += 1

        # Max drawdown (‚â§9.2%)
        dd_met = results['max_drawdown'] <= 9.2
        print(f"  ‚úÖ Max Drawdown: {results['max_drawdown']:.2f}% {'‚úÖ' if dd_met else '‚ùå'} (Target: ‚â§9.2%)")
        if dd_met: targets_met += 1

        # Profit factor (‚â•1.3)
        pf_met = results['profit_factor'] >= 1.3
        print(f"  ‚úÖ Profit Factor: {results['profit_factor']:.2f} {'‚úÖ' if pf_met else '‚ùå'} (Target: ‚â•1.3)")
        if pf_met: targets_met += 1

        # Sharpe ratio (‚â•2.2)
        sharpe_met = results['sharpe_ratio'] >= 2.2
        print(f"  ‚úÖ Sharpe Ratio: {results['sharpe_ratio']:.2f} {'‚úÖ' if sharpe_met else '‚ùå'} (Target: ‚â•2.2)")
        if sharpe_met: targets_met += 1

        print(f"\nüèÜ RC TARGETS MET: {targets_met}/{total_targets}")

        if targets_met >= 5:
            print("üéâ READY FOR RC PROMOTION!")
        elif targets_met >= 3:
            print("üîß NEEDS MINOR TUNING")
        else:
            print("‚ö†Ô∏è  NEEDS SIGNIFICANT OPTIMIZATION")

        # Show trade details
        if results['trades']:
            print(f"\nüìã ENSEMBLE TRADE HISTORY:")
            for i, trade in enumerate(results['trades'], 1):
                side = trade['side'].upper()
                entry = trade['entry_price']
                exit_p = trade.get('exit_price', 'Active')
                pnl = trade.get('pnl_pct', 0)
                reason = trade.get('exit_reason', 'active')
                tfs = trade.get('participating_tfs', [])
                timestamp = trade['entry_timestamp'].strftime('%Y-%m-%d %H:%M')

                print(f"  #{i:2d} {timestamp} | {side:5s} | "
                      f"${entry:7.2f} ‚Üí ${exit_p:7.2f} | "
                      f"PnL: {pnl:+6.2f}% | TFs: {str(tfs):15s} | {reason}")

        # Save results
        output_file = f"eth_ensemble_backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        # Convert for JSON
        json_results = {}
        for key, value in results.items():
            if key == 'trades':
                json_results[key] = []
                for trade in value:
                    trade_record = {}
                    for k, v in trade.items():
                        if hasattr(v, 'strftime'):
                            trade_record[k] = v.isoformat()
                        elif isinstance(v, (np.integer, np.floating)):
                            trade_record[k] = float(v)
                        else:
                            trade_record[k] = v
                    json_results[key].append(trade_record)
            else:
                if isinstance(value, (np.integer, np.floating)):
                    json_results[key] = float(value)
                elif isinstance(value, list):
                    json_results[key] = [float(x) if isinstance(x, (np.integer, np.floating)) else x for x in value]
                else:
                    json_results[key] = value

        with open(output_file, 'w') as f:
            json.dump(json_results, f, indent=2, default=str)

        print(f"\nüíæ Detailed results saved to: {output_file}")

    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

    print(f"\n{'='*70}")
    print(f"‚úÖ ETH Ensemble Backtest Complete!")
    print(f"{'='*70}")

if __name__ == "__main__":
    main()